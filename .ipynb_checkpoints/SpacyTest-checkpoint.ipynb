{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed8269f-ba32-4ad6-9dad-d1e6037bc9fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zhest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zhest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import LsiModel, LdaModel\n",
    "from gensim import corpora\n",
    "import spacy\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = stopwords.words('english')\n",
    "sp = spacy.load('en_core_web_lg')\n",
    "\n",
    "categories = ['rec.autos', 'comp.graphics', 'sci.space']\n",
    "newsgroup = fetch_20newsgroups(categories=categories, shuffle=True)\n",
    "data = newsgroup.data\n",
    "target = newsgroup.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66af1177-933b-459b-b873-fcd688ab8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizeNLTK(input):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #Tokenizers divide strings into lists of substrings\n",
    "    wordList = word_tokenize(input)\n",
    "    output = ' '.join([lemmatizer.lemmatize(w) for w in wordList])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40b2b78f-318d-47ea-955d-71ffd5ecd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizeSpacy(input):\n",
    "    doc = sp(input)\n",
    "    #Tokenizers divide strings into lists of substrings\n",
    "    output = ' '.join([w.lemma_ for w in doc])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3cbc387-0ded-4867-b219-8e0949ae9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NExt(input):\n",
    "    output=\"\"\n",
    "    doc = sp(input)\n",
    "    for w in doc:\n",
    "        if w.pos_==\"NOUN\":\n",
    "            output+=w.text+\" \"\n",
    "    output = output[:-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb0d038d-2961-4ec3-971a-177c44ed97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAExt(input):\n",
    "    output=\"\"\n",
    "    doc = sp(input)\n",
    "    for w in doc:\n",
    "        if w.pos_ in [\"NOUN\",\"ADJ\"]:\n",
    "            output+=w.text+\" \"\n",
    "    output = output[:-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d72d1334-3341-40d5-b3f4-908a2340216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAVExt(input):\n",
    "    output=\"\"\n",
    "    doc = sp(input)\n",
    "    for w in doc:\n",
    "        if w.pos_ in [\"NOUN\",\"ADJ\",\"VERB\"]:\n",
    "            output+=w.text+\" \"\n",
    "    output = output[:-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39dde8dd-808f-4edf-8923-7a4232b8a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NVExt(input):\n",
    "    output=\"\"\n",
    "    doc = sp(input)\n",
    "    for w in doc:\n",
    "        if w.pos_ in [\"NOUN\",\"VERB\"]:\n",
    "            output+=w.text+\" \"\n",
    "    output = output[:-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d463eaa7-3ec5-427a-ad79-c333318fb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, x_test, y_train, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    return f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2f1929f-1c48-479c-a4b5-3f1bc81fb252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcessing(unprocessedTexts, function=None):\n",
    "    if function is None:\n",
    "        return unprocessedTexts\n",
    "    return [function(text) for text in unprocessedTexts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edec5427-0587-4666-a6fd-a3bda5a9f2ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None BoW RandomForest: 0.9207380337022245\n",
      "None None BoW GBM: 0.9100258590937079\n",
      "None None TF-IDF RandomForest: 0.9369635078155392\n",
      "None None TF-IDF GBM: 0.9252082676953167\n",
      "None None LSI RandomForest: 0.6853879544659208\n",
      "None None LSI GBM: 0.7092267247910319\n",
      "None None LDA RandomForest: 0.6513513493124645\n",
      "None None LDA GBM: 0.6634030166836462\n",
      "None LemNLTK BoW RandomForest: 0.9557452449178243\n",
      "None LemNLTK BoW GBM: 0.9336367708551856\n",
      "None LemNLTK TF-IDF RandomForest: 0.9442641476070008\n",
      "None LemNLTK TF-IDF GBM: 0.9274919014659586\n",
      "None LemNLTK LSI RandomForest: 0.7417694155621958\n",
      "None LemNLTK LSI GBM: 0.7483189877424599\n",
      "None LemNLTK LDA RandomForest: 0.7524236221265924\n",
      "None LemNLTK LDA GBM: 0.7848957090580968\n",
      "None LemSpacy BoW RandomForest: 0.9438319897143427\n",
      "None LemSpacy BoW GBM: 0.9370861991540401\n",
      "None LemSpacy TF-IDF RandomForest: 0.9394686847804505\n",
      "None LemSpacy TF-IDF GBM: 0.9424790343156554\n",
      "None LemSpacy LSI RandomForest: 0.6992796513777231\n",
      "None LemSpacy LSI GBM: 0.7162393162393164\n",
      "None LemSpacy LDA RandomForest: 0.7247455444286299\n",
      "None LemSpacy LDA GBM: 0.7671848966736257\n",
      "-------------------------------------------\n",
      "Noun None BoW RandomForest: 0.9441991304745314\n",
      "Noun None BoW GBM: 0.9270757016606115\n",
      "Noun None TF-IDF RandomForest: 0.9455069998923867\n",
      "Noun None TF-IDF GBM: 0.9338851335933936\n",
      "Noun None LSI RandomForest: 0.6823876094155961\n",
      "Noun None LSI GBM: 0.6932399965201127\n",
      "Noun None LDA RandomForest: 0.7312247369837647\n",
      "Noun None LDA GBM: 0.7578432494003311\n",
      "Noun LemNLTK BoW RandomForest: 0.9409565119762732\n",
      "Noun LemNLTK BoW GBM: 0.9356842634751138\n",
      "Noun LemNLTK TF-IDF RandomForest: 0.950841943734744\n",
      "Noun LemNLTK TF-IDF GBM: 0.9250097054449751\n",
      "Noun LemNLTK LSI RandomForest: 0.726969108648498\n",
      "Noun LemNLTK LSI GBM: 0.7301787677459433\n",
      "Noun LemNLTK LDA RandomForest: 0.7192427061383891\n",
      "Noun LemNLTK LDA GBM: 0.7295268372493864\n",
      "Noun LemSpacy BoW RandomForest: 0.9337480337480337\n",
      "Noun LemSpacy BoW GBM: 0.9239705633311719\n",
      "Noun LemSpacy TF-IDF RandomForest: 0.9389692306964893\n",
      "Noun LemSpacy TF-IDF GBM: 0.9234478710319269\n",
      "Noun LemSpacy LSI RandomForest: 0.6756580386543675\n",
      "Noun LemSpacy LSI GBM: 0.68654031726613\n",
      "Noun LemSpacy LDA RandomForest: 0.7241861578707737\n",
      "Noun LemSpacy LDA GBM: 0.7465926501059319\n",
      "-------------------------------------------\n",
      "Noun+Adj None BoW RandomForest: 0.9405770820113034\n",
      "Noun+Adj None BoW GBM: 0.9299992591552809\n",
      "Noun+Adj None TF-IDF RandomForest: 0.9257952493554588\n",
      "Noun+Adj None TF-IDF GBM: 0.9306953366990891\n",
      "Noun+Adj None LSI RandomForest: 0.6833973825014554\n",
      "Noun+Adj None LSI GBM: 0.7060454943520157\n",
      "Noun+Adj None LDA RandomForest: 0.7109682672112849\n",
      "Noun+Adj None LDA GBM: 0.7316532911763586\n",
      "Noun+Adj LemNLTK BoW RandomForest: 0.9289683595038595\n",
      "Noun+Adj LemNLTK BoW GBM: 0.9155373470322171\n",
      "Noun+Adj LemNLTK TF-IDF RandomForest: 0.945708282488027\n",
      "Noun+Adj LemNLTK TF-IDF GBM: 0.935192651022355\n",
      "Noun+Adj LemNLTK LSI RandomForest: 0.7243775941724244\n",
      "Noun+Adj LemNLTK LSI GBM: 0.7273819527818038\n",
      "Noun+Adj LemNLTK LDA RandomForest: 0.7009889374029663\n",
      "Noun+Adj LemNLTK LDA GBM: 0.7385377732168462\n",
      "Noun+Adj LemSpacy BoW RandomForest: 0.9491995740745746\n",
      "Noun+Adj LemSpacy BoW GBM: 0.9389854546500263\n",
      "Noun+Adj LemSpacy TF-IDF RandomForest: 0.9404189958964463\n",
      "Noun+Adj LemSpacy TF-IDF GBM: 0.9254514466229358\n",
      "Noun+Adj LemSpacy LSI RandomForest: 0.6635117869000223\n",
      "Noun+Adj LemSpacy LSI GBM: 0.6976803216913295\n",
      "Noun+Adj LemSpacy LDA RandomForest: 0.7258070751295008\n",
      "Noun+Adj LemSpacy LDA GBM: 0.7688891354130439\n",
      "-------------------------------------------\n",
      "Noun+Adj+Verb None BoW RandomForest: 0.9391401211318156\n",
      "Noun+Adj+Verb None BoW GBM: 0.9318406866138825\n",
      "Noun+Adj+Verb None TF-IDF RandomForest: 0.9387025973738657\n",
      "Noun+Adj+Verb None TF-IDF GBM: 0.9336674184822117\n",
      "Noun+Adj+Verb None LSI RandomForest: 0.7171180092981343\n",
      "Noun+Adj+Verb None LSI GBM: 0.7249592877881313\n",
      "Noun+Adj+Verb None LDA RandomForest: 0.6613781796448099\n",
      "Noun+Adj+Verb None LDA GBM: 0.6972055931515349\n",
      "Noun+Adj+Verb LemNLTK BoW RandomForest: 0.9421337545121806\n",
      "Noun+Adj+Verb LemNLTK BoW GBM: 0.9184156691762744\n",
      "Noun+Adj+Verb LemNLTK TF-IDF RandomForest: 0.9421183171461258\n",
      "Noun+Adj+Verb LemNLTK TF-IDF GBM: 0.9472406186649245\n",
      "Noun+Adj+Verb LemNLTK LSI RandomForest: 0.7403140615689344\n",
      "Noun+Adj+Verb LemNLTK LSI GBM: 0.7608920289332661\n",
      "Noun+Adj+Verb LemNLTK LDA RandomForest: 0.7656823268100823\n",
      "Noun+Adj+Verb LemNLTK LDA GBM: 0.7834599514535395\n",
      "Noun+Adj+Verb LemSpacy BoW RandomForest: 0.9373896330005934\n",
      "Noun+Adj+Verb LemSpacy BoW GBM: 0.9252698121409981\n",
      "Noun+Adj+Verb LemSpacy TF-IDF RandomForest: 0.9405345910985364\n",
      "Noun+Adj+Verb LemSpacy TF-IDF GBM: 0.901285005195441\n",
      "Noun+Adj+Verb LemSpacy LSI RandomForest: 0.687253974850874\n",
      "Noun+Adj+Verb LemSpacy LSI GBM: 0.7247152063425539\n",
      "Noun+Adj+Verb LemSpacy LDA RandomForest: 0.6811191737536131\n",
      "Noun+Adj+Verb LemSpacy LDA GBM: 0.6848848685453459\n",
      "-------------------------------------------\n",
      "Noun+Verb None BoW RandomForest: 0.9490874532756757\n",
      "Noun+Verb None BoW GBM: 0.9271283898209343\n",
      "Noun+Verb None TF-IDF RandomForest: 0.942251827902036\n",
      "Noun+Verb None TF-IDF GBM: 0.9216682494460271\n",
      "Noun+Verb None LSI RandomForest: 0.7127982036908468\n",
      "Noun+Verb None LSI GBM: 0.726811277032916\n",
      "Noun+Verb None LDA RandomForest: 0.7363884777831883\n",
      "Noun+Verb None LDA GBM: 0.752059288129112\n",
      "Noun+Verb LemNLTK BoW RandomForest: 0.9473532321041936\n",
      "Noun+Verb LemNLTK BoW GBM: 0.933522400236443\n",
      "Noun+Verb LemNLTK TF-IDF RandomForest: 0.9383007384945178\n",
      "Noun+Verb LemNLTK TF-IDF GBM: 0.9336408672268298\n",
      "Noun+Verb LemNLTK LSI RandomForest: 0.7196963779189648\n",
      "Noun+Verb LemNLTK LSI GBM: 0.7076714887774795\n",
      "Noun+Verb LemNLTK LDA RandomForest: 0.7450337230785742\n",
      "Noun+Verb LemNLTK LDA GBM: 0.7478549963313555\n",
      "Noun+Verb LemSpacy BoW RandomForest: 0.9270315676151181\n",
      "Noun+Verb LemSpacy BoW GBM: 0.9199752879453652\n",
      "Noun+Verb LemSpacy TF-IDF RandomForest: 0.9278139051332033\n",
      "Noun+Verb LemSpacy TF-IDF GBM: 0.9240686285872856\n",
      "Noun+Verb LemSpacy LSI RandomForest: 0.6762993231066116\n",
      "Noun+Verb LemSpacy LSI GBM: 0.6991270022752422\n",
      "Noun+Verb LemSpacy LDA RandomForest: 0.8071025347682029\n",
      "Noun+Verb LemSpacy LDA GBM: 0.8071395816658974\n",
      "-------------------------------------------\n",
      "Maximum: 0.9557452449178243\n",
      "None LemNLTK BoW RandomForest\n"
     ]
    }
   ],
   "source": [
    "mapPreProc = [\"None\",\"Noun\",\"Noun+Adj\",\"Noun+Adj+Verb\",\"Noun+Verb\"]\n",
    "mapProc = [\"None\", \"LemNLTK\", \"LemSpacy\"]\n",
    "mapVec = [\"BoW\",\"TF-IDF\",\"LSI\",\"LDA\"]\n",
    "mapClf= [\"RandomForest\",\"GBM\"]\n",
    "list=[]\n",
    "for i in range(5):\n",
    "    if i==0:\n",
    "        preProc=None\n",
    "    if i==1:\n",
    "        preProc=NExt\n",
    "    if i==2:\n",
    "        preProc=NAExt\n",
    "    if i==3:\n",
    "        preProc=NAVExt\n",
    "    if i==4:\n",
    "        preProc=NVExt\n",
    "    dataExt = textProcessing(data,preProc)\n",
    "    for j in range(3):\n",
    "        if j==0:\n",
    "            proc=None\n",
    "        if j==1:\n",
    "            proc=lemmatizeNLTK\n",
    "        if j==2:\n",
    "            proc=lemmatizeSpacy\n",
    "        dataProc = textProcessing(data,proc)\n",
    "        tokenized_documents = [simple_preprocess(text) for text in dataProc]\n",
    "        dictionary = corpora.Dictionary(tokenized_documents)\n",
    "        bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_documents]\n",
    "        lsi = LsiModel(bow_corpus,id2word=dictionary, num_topics=10)\n",
    "        lda = LdaModel(bow_corpus, num_topics=25, id2word=dictionary,passes=15, minimum_probability = 0)\n",
    "        for k in range(4):\n",
    "            if k==0:\n",
    "                vect = CountVectorizer(binary=False, stop_words=stop_words)\n",
    "            if k==1:\n",
    "                vect = TfidfVectorizer(stop_words=stop_words)\n",
    "            if k==2:\n",
    "                func = lsi\n",
    "            if k==3:\n",
    "                func = lda\n",
    "            X_train, X_test, y_train, y_test = [],[],[],[]\n",
    "            if k in [0,1]:\n",
    "                trainProc, testProc, y_train, y_test = train_test_split(dataProc, target, test_size=0.33)\n",
    "                X_train = vect.fit_transform(trainProc)\n",
    "                X_test = vect.transform(testProc)\n",
    "            else:\n",
    "                dataVecPre = func[bow_corpus]\n",
    "                len_data = len(dataVecPre)\n",
    "                dataVec = [0 for o in range(len_data)]\n",
    "                for o in range(len_data):\n",
    "                    curr = []\n",
    "                    a = dataVecPre[o]\n",
    "                    length = len(a)\n",
    "                    curr = [a[u][1] for u in range(length)]\n",
    "                    dataVec[o] = curr\n",
    "                X_train, X_test, y_train, y_test = train_test_split(dataVec, target, test_size=0.33)\n",
    "            for l in range(2):\n",
    "                if l==0:\n",
    "                    clf = RandomForestClassifier()\n",
    "                if l==1:\n",
    "                    clf = GradientBoostingClassifier(n_estimators=125)\n",
    "                f1 = train(X_train, X_test, y_train, y_test, clf)\n",
    "                s = \" \".join([mapPreProc[i],mapProc[j],mapVec[k],mapClf[l]])\n",
    "                list.append([f1,s])\n",
    "                print(s+\": \"+str(f1))\n",
    "    print(\"-------------------------------------------\")\n",
    "listMax = [el[0] for el in list]\n",
    "maximum = max(listMax)\n",
    "print(f\"Maximum: {maximum}\")\n",
    "print(list[listMax.index(maximum)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23ca2a-e675-461a-81a7-de514c0a4d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
