{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e9dab756-2ebc-42c1-8f18-4ad19b29754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2950,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import TfidfModel, LdaModel\n",
    "from gensim import corpora\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "categories = ['rec.autos', 'comp.graphics', 'sci.space']\n",
    "newsgroup = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "print(newsgroup.filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2f11a159-f0a0-40d3-a3a8-19f2515f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_documents = [simple_preprocess(text) for text in newsgroup.data]\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_documents]\n",
    "modelTf = TfidfModel(bow_corpus)\n",
    "tf_corpus = [modelTf[corpus_item] for corpus_item in bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "69487c68-5a3c-47ba-8eb7-659cd03d7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "07ccbbac-1eb4-421c-b741-81a29f22c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:15,result is 0.5484808136068366\n",
      "N:20,result is 0.4608220302375758\n",
      "N:25,result is 0.49287386055678734\n",
      "N:30,result is 0.4843593410237233\n",
      "N:40,result is 0.5581355556950541\n",
      "N:50,result is 0.5216011295369951\n",
      "N:75,result is 0.5576574937956097\n",
      "N:80,result is 0.530712778385475\n",
      "N:85,result is 0.5843322984228807\n",
      "N:90,result is 0.6286907409655756\n",
      "N:100,result is 0.607895615253138\n",
      "N:110,result is 0.6084458959465465\n",
      "N:120,result is 0.6223888243894756\n",
      "N:140,result is 0.5794906899622526\n",
      "N:150,result is 0.5484212178242035\n",
      "N:170,result is 0.6727900344881567\n",
      "N:180,result is 0.6394013537863719\n",
      "N:190,result is 0.6401426308097672\n",
      "N:200,result is 0.6263596067733478\n"
     ]
    }
   ],
   "source": [
    "for n in [15,20,25,30,40,50,75,80,85,90,100,110,120,140,150,170,180,190,200]:\n",
    "    lda = LdaModel(tf_corpus, num_topics=n, id2word=dictionary,passes=15, minimum_probability = 0)\n",
    "    vectorized_corpus = lda[tf_corpus]\n",
    "    vectorized_corpus_new = [0 for i in range(2950)]\n",
    "    for i in range(len(vectorized_corpus)):\n",
    "        curr = []\n",
    "        a = vectorized_corpus[i]\n",
    "        length = len(a)\n",
    "        curr = [a[j][1] for j in range(n)]\n",
    "        vectorized_corpus_new[i] = curr\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vectorized_corpus_new, newsgroup.target, test_size=0.33)\n",
    "    print(f\"N:{n},result is {train(X_train, X_test, y_train, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fbf1e-e07f-4404-9be9-9ec0f76d5ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
